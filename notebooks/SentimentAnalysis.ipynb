{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"imdb.ipynb","provenance":[],"authorship_tag":"ABX9TyMA9+QeHnqnYKVShVvw/Hjs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"-_nrMQ7UaRJ4","colab_type":"text"},"source":["NLP WORKSHOP"]},{"cell_type":"code","metadata":{"id":"gIk7HDgyZRnN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"status":"ok","timestamp":1600979415031,"user_tz":-120,"elapsed":1085,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}},"outputId":"61837830-51c6-4780-a312-9ad4a5997e34"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Thu Sep 24 20:30:45 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   67C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v03ZFeVNSi_J","colab_type":"code","colab":{}},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zaLlMmyyRPx9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600988560449,"user_tz":-120,"elapsed":638,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n","from torch.utils.tensorboard import SummaryWriter\n","from transformers import BertModel, BertConfig, BertTokenizerFast, get_linear_schedule_with_warmup, AdamW\n","from transformers import DistilBertConfig, DistilBertModel, DistilBertTokenizerFast\n","from sklearn.model_selection import train_test_split\n","import os\n","from tqdm import tqdm, trange\n","import numpy as np\n","import pandas as pd\n","from dataclasses import dataclass"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"3O0LGwKPTtQ7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600979457876,"user_tz":-120,"elapsed":614,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["class TextClassificationDataset(Dataset):\n","    def __init__(self, inputs, labels, tokenizer, max_len):\n","        super(TextClassificationDataset, self).__init__()\n","\n","        encoded_inputs = tokenizer(inputs, max_length=max_len, padding=\"max_length\", truncation=True)\n","        self.data = list(zip(encoded_inputs[\"input_ids\"], encoded_inputs[\"attention_mask\"], labels))\n","\n","    def __getitem__(self, i):\n","        return self.data[i]\n","\n","    def __len__(self):\n","        return len(self.data)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ix0p11FITwZL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600979542312,"user_tz":-120,"elapsed":684,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["class BertTextClassificationModel(nn.Module):\n","    def __init__(self, bert_config, num_classes, dropout_prob=0.1):\n","        super(BertTextClassificationModel, self).__init__()\n","\n","        self.bert = BertModel(bert_config)\n","        self.dropout = nn.Dropout(dropout_prob)\n","        self.classification_layer = nn.Linear(in_features=bert_config.hidden_size, out_features=num_classes)\n","\n","    def forward(self, x):\n","        outputs = self.bert(input_ids=x[\"input_ids\"], attention_mask=x[\"attention_mask\"])\n","        cls = outputs[1]\n","        cls = self.dropout(cls)\n","        return self.classification_layer(cls)\n","\n","    def load(self, path_to_dir):\n","        self.bert = BertModel.from_pretrained(path_to_dir)\n","        model_path = os.path.join(path_to_dir, \"model.tar\")\n","        if os.path.exists(model_path):\n","            checkpoint = torch.load(model_path)\n","            self.dropout.load_state_dict(checkpoint[\"dropout\"])\n","            self.classification_layer.load_state_dict(checkpoint[\"cls\"])\n","            print(\"No model.tar in provided directory, only loading bert model.\")\n","\n","    def save(self, path_to_dir):\n","        self.bert.save_pretrained(path_to_dir)\n","        torch.save(\n","            {\"dropout\": self.dropout.state_dict(), \"cls\": self.classification_layer.state_dict()},\n","            os.path.join(path_to_dir, \"model.tar\")\n","        )"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"f9DJ7zzjVlbI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600988995182,"user_tz":-120,"elapsed":656,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["class DistilBertTextClassificationModel(nn.Module):\n","    def __init__(self, bert_config, num_classes, dropout_prob=0.1):\n","        super(DistilBertTextClassificationModel, self).__init__()\n","\n","        self.bert = DistilBertModel(bert_config)\n","        self.dropout = nn.Dropout(dropout_prob)\n","        self.classification_layer = nn.Linear(in_features=bert_config.hidden_size, out_features=num_classes)\n","\n","    def forward(self, x):\n","        outputs = self.bert(input_ids=x[\"input_ids\"], attention_mask=x[\"attention_mask\"])[0]\n","        cls = outputs[:, 0, :]  # cls is the first token of the sequence\n","        cls = self.dropout(cls)\n","        return self.classification_layer(cls)\n","\n","    def load(self, path_to_dir):\n","        self.bert = DistilBertModel.from_pretrained(path_to_dir)\n","        model_path = os.path.join(path_to_dir, \"model.tar\")\n","        if os.path.exists(model_path):\n","            checkpoint = torch.load(model_path)\n","            self.dropout.load_state_dict(checkpoint[\"dropout\"])\n","            self.classification_layer.load_state_dict(checkpoint[\"cls\"])\n","            print(\"No model.tar in provided directory, only loading bert model.\")\n","\n","    def save(self, path_to_dir):\n","        self.bert.save_pretrained(path_to_dir)\n","        torch.save(\n","            {\"dropout\": self.dropout.state_dict(), \"cls\": self.classification_layer.state_dict()},\n","            os.path.join(path_to_dir, \"model.tar\")\n","        )"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"9nczsxRuT32m","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600979545292,"user_tz":-120,"elapsed":550,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["def text_classification_collate(inputs):\n","    # groups selected inputs into a batch -> tuple (x, y)\n","    batch = (\n","        {\"input_ids\": torch.tensor([dat[0] for dat in inputs], dtype=torch.long),\n","         \"attention_mask\": torch.tensor([dat[1] for dat in inputs], dtype=torch.long)},\n","        torch.tensor([dat[2] for dat in inputs], dtype=torch.long))\n","    return batch"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xzb97r2yT9VR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600979547088,"user_tz":-120,"elapsed":589,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["def train(model, train_dataset, val_dataset, loss_fn, device, run_config):\n","    if not os.path.isdir(run_config.output_dir):\n","        os.makedirs(run_config.output_dir)\n","    tb_writer = SummaryWriter(log_dir=os.path.join(run_config.output_dir, \"tensorboard\"))\n","\n","    train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=run_config.batch_size,\n","                                  collate_fn=text_classification_collate)\n","    print(len(train_dataloader)) # todo delete\n","\n","    optimizer = AdamW(model.parameters(), lr=run_config.learning_rate)\n","    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=run_config.num_warmup_steps,\n","                                                num_training_steps=len(train_dataloader)*run_config.num_epochs)\n","    print(\"Training started:\")\n","    print(f\"\\tNum examples = {len(train_dataset)}\")\n","    print(f\"\\tNum Epochs = {run_config.num_epochs}\",)\n","\n","    train_iterator = trange(0, int(run_config.num_epochs), desc=\"Epoch\")\n","    for epoch in train_iterator:\n","        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", position=0, leave=True)\n","        model.train()\n","        epoch_losses = []\n","        for step, (x, y) in enumerate(epoch_iterator):\n","            # move batch to GPU\n","            if isinstance(x, dict):\n","                for k, v in x.items():\n","                    x[k] = v.to(device)\n","            else:\n","                x = x.to(device)\n","            y = y.to(device)\n","\n","            # forward pass to compute logits\n","            logits_y = model(x)\n","\n","            loss = loss_fn(logits_y, y)\n","            epoch_losses.append(loss.item())\n","\n","            # backward pass - backprop\n","            model.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","\n","            epoch_iterator.set_description(f\"Training loss = {loss.item():.4f}\")\n","\n","        output_dir = os.path.join(run_config.output_dir, f\"Epoch_{epoch + 1}\")\n","        model.save(output_dir)  # we save after each epoch, perhaps an improvement is to save after n steps\n","        # evaluate and write to tensorboard\n","        test_ce, test_acc = evaluate(model, val_dataset, device, run_config)\n","        tb_writer.add_scalar(\"Avg Train CE\", np.mean(epoch_losses), epoch + 1)\n","        tb_writer.add_scalar(\"Test CE\", test_ce, epoch + 1)\n","        tb_writer.add_scalar(\"Test accuracy\", test_acc, epoch + 1)\n","        print(f\"After epoch {epoch + 1}: \\n-train CE={np.mean(epoch_losses)}\\n-test CE={test_ce}\\n-test acc.={test_acc}\")\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"CqPrFNCMUJ0G","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600979549863,"user_tz":-120,"elapsed":573,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["def evaluate(model, test_dataset, device, run_config):\n","    test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset),\n","                                 batch_size=run_config.batch_size, collate_fn=text_classification_collate)\n","    model.eval()\n","    ce_losses, acc_losses = [], []\n","    with torch.no_grad():\n","      for batch in tqdm(test_dataloader, desc=\"Evaluating\", position=0, leave=True):\n","          x, y = batch\n","          # move batch to GPU\n","          if isinstance(x, dict):\n","              for k, v in x.items():\n","                  x[k] = v.to(device)\n","          else:\n","              x = x.to(device)\n","          y = y.to(device)\n","\n","          logits_y = model(x)\n","          ce_losses.append(nn.functional.cross_entropy(logits_y, y).item())\n","          pred_y = np.argmax(nn.functional.softmax(logits_y, dim=1).squeeze().detach().cpu().numpy(), axis=1)  # beautiful\n","          true_y = y.cpu().numpy()\n","          acc_losses.append(np.mean(pred_y == true_y))\n","\n","    return np.mean(ce_losses), np.mean(acc_losses)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"nfocadzaULSF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600979982714,"user_tz":-120,"elapsed":587,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["@dataclass\n","class RunConfig:\n","    learning_rate: float = 3e-5\n","    batch_size: int = 4\n","    num_epochs: int = 1\n","    num_warmup_steps: int = 10\n","    max_len: int = 512\n","    output_dir: str = \"./model/\""],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"nRmvKyEKU6-A","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600979953028,"user_tz":-120,"elapsed":15225,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}},"outputId":"cd9e062d-a8b1-4d64-b140-39377342d3c0"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive/\")"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O01JBtlsVbCa","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600989213610,"user_tz":-120,"elapsed":583,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["run_config = RunConfig(\n","    batch_size = 32,\n","    num_epochs = 20,\n","    output_dir = \"/content/drive/My Drive/NLP workshop/imdb/distill/\"\n",")"],"execution_count":67,"outputs":[]},{"cell_type":"code","metadata":{"id":"bIfRX1KTWC8o","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600980000827,"user_tz":-120,"elapsed":2231,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["path_to_train_csv = \"/content/drive/My Drive/NLP workshop/imdb/imdb_train.csv\"\n","\n","sentiment_to_label = {\"negative\": 0, \"positive\": 1}\n","label_to_sentiment = {0: \"negative\", 1: \"positive\"}\n","\n","df = pd.read_csv(path_to_train_csv)\n","df[\"label\"] = df[\"sentiment\"].map(sentiment_to_label)\n","train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"])"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"cpQGbZgxWyQ6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600989241259,"user_tz":-120,"elapsed":25303,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["# tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-cased\")\n","tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\", do_lower_case=True)\n","\n","train_dataset = TextClassificationDataset(train_df[\"review\"].tolist(), train_df[\"label\"].tolist(), tokenizer, run_config.max_len)\n","val_dataset = TextClassificationDataset(val_df[\"review\"].tolist(), val_df[\"label\"].tolist(), tokenizer, run_config.max_len)\n","\n","# model = BertTextClassificationModel(BertConfig.from_pretrained(\"bert-base-cased\"), num_classes=2)\n","# model.load(\"bert-base-cased\")\n","\n","model = DistilBertTextClassificationModel(DistilBertConfig.from_pretrained(\"distilbert-base-uncased\"), num_classes=2)\n","model.load(\"distilbert-base-uncased\")"],"execution_count":68,"outputs":[]},{"cell_type":"code","metadata":{"id":"zaXngyTXXOMk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600989246845,"user_tz":-120,"elapsed":597,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)"],"execution_count":69,"outputs":[]},{"cell_type":"code","metadata":{"id":"VedKMg4cW0Tx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":825},"executionInfo":{"status":"error","timestamp":1600994653252,"user_tz":-120,"elapsed":5394546,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}},"outputId":"b8b42170-bd9f-4515-bb75-31bca481e800"},"source":["train(model, train_dataset, val_dataset, nn.CrossEntropyLoss().to(device), device, run_config)"],"execution_count":71,"outputs":[{"output_type":"stream","text":["\n","\n","Iteration:   0%|          | 0/1000 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["1000\n","Training started:\n","\tNum examples = 32000\n","\tNum Epochs = 20\n"],"name":"stdout"},{"output_type":"stream","text":["Training loss CE = 0.2325: 100%|██████████| 1000/1000 [27:28<00:00,  1.64s/it]\n","\u001b[A\n","\n","Training loss CE = 0.2325: 100%|██████████| 1000/1000 [27:28<00:00,  1.65s/it]\n","Evaluating: 100%|██████████| 250/250 [02:26<00:00,  1.70it/s]\n","Evaluating: 100%|██████████| 250/250 [02:26<00:00,  1.70it/s]\n","Iteration:   0%|          | 0/1000 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["After epoch 1: \n","-train CE=0.2325395093653351\n","-test CE=0.21761479644477366\n","-test acc.=0.925375\n"],"name":"stdout"},{"output_type":"stream","text":["Training loss CE = 0.1215: 100%|██████████| 1000/1000 [27:27<00:00,  1.65s/it]\n","Evaluating: 100%|██████████| 250/250 [02:27<00:00,  1.70it/s]\n","Iteration:   0%|          | 0/1000 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["After epoch 2: \n","-train CE=0.12146003976743669\n","-test CE=0.19302185540646313\n","-test acc.=0.93275\n"],"name":"stdout"},{"output_type":"stream","text":["Training loss CE = 0.0585: 100%|██████████| 1000/1000 [27:25<00:00,  1.65s/it]\n","Evaluating: 100%|██████████| 250/250 [02:26<00:00,  1.70it/s]\n","Iteration:   0%|          | 0/1000 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["After epoch 3: \n","-train CE=0.05851310090336483\n","-test CE=0.22955984109267594\n","-test acc.=0.933375\n"],"name":"stdout"},{"output_type":"stream","text":["Training loss CE = 0.0098:   0%|          | 4/1000 [00:06<27:16,  1.64s/it]"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-71-e724372f0f3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-509258a470d7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataset, val_dataset, loss_fn, device, run_config)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mepoch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m# backward pass - backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"hkYI1qCLX1fl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600989203768,"user_tz":-120,"elapsed":1779,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["model = None\n","train_dataloder = None\n","epoch_iterator = None\n","x, y = None, None\n","loss, optimizer = None, None\n","logits_y = None\n","scheduler = None\n","import gc\n","gc.collect()\n","torch.cuda.empty_cache()"],"execution_count":64,"outputs":[]},{"cell_type":"code","metadata":{"id":"dicGb2R2YhmW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"status":"ok","timestamp":1600989254510,"user_tz":-120,"elapsed":691,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}},"outputId":"c871128e-83e9-4a02-8957-516ce6b69e29"},"source":["!nvidia-smi"],"execution_count":70,"outputs":[{"output_type":"stream","text":["Thu Sep 24 23:14:44 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   77C    P0    34W /  70W |   1283MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9bLHZEoaY_I8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":171},"executionInfo":{"status":"error","timestamp":1600989194977,"user_tz":-120,"elapsed":632,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}},"outputId":"fe25568a-a9eb-4863-bd5f-c127cd78877a"},"source":["1/0"],"execution_count":62,"outputs":[{"output_type":"error","ename":"ZeroDivisionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-62-9e1622b385b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"]}]},{"cell_type":"code","metadata":{"id":"28oJVEok8enw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600995232835,"user_tz":-120,"elapsed":556,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["idx = 4\n","text = train_df[\"review\"].tolist()[idx]\n","text = \"I fell asleep six minutes into the movie.\"\n","text = \"It sucked!\"\n","text = \"It was so good.\"\n","gt = train_df[\"label\"].tolist()[idx]\n","enc = tokenizer(text)\n","input_to_model = {\"input_ids\": torch.tensor(enc[\"input_ids\"], dtype=torch.long).unsqueeze(0).to(device),\n","                  \"attention_mask\": torch.tensor(enc[\"attention_mask\"], dtype=torch.long).unsqueeze(0).to(device)}"],"execution_count":92,"outputs":[]},{"cell_type":"code","metadata":{"id":"jtmvctjT84wi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1600995234603,"user_tz":-120,"elapsed":604,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}},"outputId":"b327ecef-be57-4085-905e-ed222ba3c2a5"},"source":["model.eval()\n","with torch.no_grad():\n","  print(gt)\n","  print(model(input_to_model))\n","  print(nn.functional.softmax(model(input_to_model), dim=1))"],"execution_count":93,"outputs":[{"output_type":"stream","text":["1\n","tensor([[-1.8024,  2.1634]], device='cuda:0')\n","tensor([[0.0186, 0.9814]], device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6ljH_qBIuqPl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600995237959,"user_tz":-120,"elapsed":577,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}},"outputId":"6df36681-1efa-4110-f6f9-b0db333619ca"},"source":["print(review_to_sentiment(model, tokenizer, label_to_sentiment, device, text))"],"execution_count":94,"outputs":[{"output_type":"stream","text":["positive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cOTMXIa_uGgz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600995214467,"user_tz":-120,"elapsed":541,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["def review_to_sentiment(model, tokenizer, label_to_sentiment, device, review):\n","  x = tokenizer.encode_plus(text, return_tensors=\"pt\").to(device)\n","  with torch.no_grad():\n","    pred = np.argmax(nn.functional.softmax(model(x), dim=1).cpu().numpy(), axis=1)[0]\n","  return label_to_sentiment.get(pred)"],"execution_count":90,"outputs":[]},{"cell_type":"code","metadata":{"id":"lz8bls6Pwccc","colab_type":"code","colab":{}},"source":["# todo above: evaluate on test set"],"execution_count":null,"outputs":[]}]}