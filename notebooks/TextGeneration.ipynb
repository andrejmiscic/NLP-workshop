{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"quotes.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMBCgZ2RHs3tF63nsa4/3wd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Mk987z0XybLv","executionInfo":{"status":"ok","timestamp":1601118412155,"user_tz":-120,"elapsed":1274,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}},"outputId":"30e59fec-dce0-4e69-d230-0817fa4a6c3f","colab":{"base_uri":"https://localhost:8080/","height":380}},"source":["!nvidia-smi"],"execution_count":84,"outputs":[{"output_type":"stream","text":["Sat Sep 26 11:07:23 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   47C    P0    35W / 250W |   1427MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fzdzzTt1yu6a"},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IF340TQBy0bE","executionInfo":{"status":"ok","timestamp":1601116597026,"user_tz":-120,"elapsed":806,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n","from torch.optim import AdamW\n","from transformers import GPT2TokenizerFast, TextDataset, GPT2LMHeadModel, DataCollatorForLanguageModeling, GPT2Tokenizer, get_linear_schedule_with_warmup\n","import random\n","from sklearn.model_selection import train_test_split\n","import os\n","from tqdm import tqdm, trange\n","import numpy as np\n","from dataclasses import dataclass\n","import itertools"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"WHI5aDbFy6hh","executionInfo":{"status":"ok","timestamp":1601116769364,"user_tz":-120,"elapsed":922,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["class LinesTextDatasetWithEpochs(Dataset):\n","    def __init__(self, examples, tokenizer, block_size, num_epochs, example_del=\"<|endoftext|>\"):\n","        super(LinesTextDatasetWithEpochs, self).__init__()\n","        examples_input_ids = []\n","        for ex in examples:\n","            examples_input_ids.append(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(example_del + ex)))\n","\n","        combined_input_ids = []\n","        for i in range(num_epochs):\n","            tmp = examples_input_ids.copy()\n","            random.shuffle(tmp)\n","            combined_input_ids.extend(list(itertools.chain.from_iterable(tmp)))\n","\n","        self.data = []\n","        for i in range(0, len(combined_input_ids) - block_size + 1, block_size):\n","            self.data.append(tokenizer.build_inputs_with_special_tokens(combined_input_ids[i: i + block_size]))\n","\n","    def __getitem__(self, i):\n","        return torch.tensor(self.data[i], dtype=torch.long)\n","\n","    def __len__(self):\n","        return len(self.data)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"3jUc4B5yy96h","executionInfo":{"status":"ok","timestamp":1601118398561,"user_tz":-120,"elapsed":934,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["def train(model, train_dataset, val_dataset, device, run_config, collate_fn):\n","    if not os.path.isdir(run_config.output_dir):\n","        os.makedirs(run_config.output_dir)\n","\n","    train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=run_config.batch_size,\n","                                  collate_fn=collate_fn)\n","\n","    optimizer = AdamW(model.parameters(), lr=run_config.learning_rate)\n","    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=run_config.num_warmup_steps,\n","                                                num_training_steps=len(train_dataloader)*run_config.num_epochs)\n","    print(\"Training started:\")\n","    print(f\"\\tNum examples = {len(train_dataset)}\")\n","    print(f\"\\tNum Epochs = {run_config.num_epochs}\")\n","\n","    print((len(train_dataset) // 8))  # todo delete\n","\n","    # train_iterator = trange(0, int(run_config.num_epochs), desc=\"Epoch\")\n","    train_iterator = trange(0, 1, desc=\"Epoch\")\n","    for epoch in train_iterator:\n","        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", position=0, leave=True)\n","        model.train()\n","        epoch_losses = []\n","        for step, inputs in enumerate(epoch_iterator):\n","            # move batch to GPU\n","            if isinstance(inputs, dict):\n","                for k, v in inputs.items():\n","                    inputs[k] = v.to(device)\n","            else:\n","                inputs = inputs.to(device)\n","\n","            # forward pass to compute logits\n","            outputs = model(**inputs)\n","            loss = outputs[0]\n","\n","            epoch_losses.append(loss.item())\n","\n","            # backward pass - backprop\n","            model.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","\n","            epoch_iterator.set_description(f\"Training loss = {loss.item():.4f}\")\n","\n","            if step > 0 and step % (len(train_dataloader) // run_config.num_epochs) == 0:\n","              output_dir = os.path.join(run_config.output_dir, f\"Step_{step}\")\n","              model.save_pretrained(output_dir)\n","              test_ce = evaluate(model, val_dataset, device, run_config, collate_fn)\n","              print(f\"After step {step + 1}: \\n-train CE={np.mean(epoch_losses)}\\n-testCE={test_ce}\")\n","\n","        output_dir = os.path.join(run_config.output_dir, f\"Epoch_{epoch + 1}\")\n","        model.save_pretrained(output_dir) \n"],"execution_count":82,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fby8X5bQzBrr","executionInfo":{"status":"ok","timestamp":1601119076603,"user_tz":-120,"elapsed":1464,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["def evaluate(model, test_dataset, device, run_config, collate_fn):\n","    test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset),\n","                                 batch_size=run_config.batch_size, collate_fn=collate_fn)\n","    model.eval()\n","    ce_losses = []\n","    for inputs in tqdm(test_dataloader, desc=\"Evaluating\", position=0, leave=True):\n","        # move batch to GPU\n","        if isinstance(inputs, dict):\n","            for k, v in inputs.items():\n","                inputs[k] = v.to(device)\n","        else:\n","            inputs = inputs.to(device)\n","\n","        with torch.no_grad():\n","            loss = model(**inputs)[0]\n","        ce_losses.append(loss.item())\n","\n","    return np.mean(ce_losses)"],"execution_count":86,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mxxs36yBz2cq","executionInfo":{"status":"ok","timestamp":1601116530223,"user_tz":-120,"elapsed":873,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["@dataclass\n","class RunConfig:\n","    learning_rate: float = 3e-5\n","    batch_size: int = 4\n","    num_epochs: int = 1\n","    num_warmup_steps: int = 10\n","    max_len: int = 512\n","    output_dir: str = \"./model/\"\n","    block_size = 128"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"m8wqypP50Agv","executionInfo":{"status":"ok","timestamp":1601116550273,"user_tz":-120,"elapsed":18949,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}},"outputId":"afd2b8fa-eed2-46bd-97c4-4e18ee847b90","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount(\"/content/drive/\")"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fqa2p-ay0Jvi","executionInfo":{"status":"ok","timestamp":1601116558831,"user_tz":-120,"elapsed":787,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["run_config = RunConfig(\n","    batch_size = 32,\n","    num_epochs = 5,\n","    output_dir = \"/content/drive/My Drive/NLP workshop/quotes\"\n",")"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"3cM9Pzr70R_o"},"source":["with open(\"/content/drive/My Drive/NLP workshop/quotes/quotes_train.txt\", \"r\") as f:\n","    examples = [l.strip() for l in f.readlines()]\n","\n","train_examples, valid_examples = train_test_split(examples, test_size=0.2)\n","\n","tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n","collate_call = DataCollatorForLanguageModeling(tokenizer, mlm=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uJDF44dQ0x6h","executionInfo":{"status":"ok","timestamp":1601116782028,"user_tz":-120,"elapsed":7266,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["train_dataset = LinesTextDatasetWithEpochs(train_examples, tokenizer, run_config.block_size, run_config.num_epochs)\n","val_dataset = LinesTextDatasetWithEpochs(valid_examples, tokenizer, run_config.block_size, 1)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"YChnZACnIe9h"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IKJ9_tAgimDn","executionInfo":{"status":"ok","timestamp":1601118408519,"user_tz":-120,"elapsed":6621,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)"],"execution_count":83,"outputs":[]},{"cell_type":"code","metadata":{"id":"DCkHfv94i1Rg"},"source":["train(model, train_dataset, val_dataset, device, run_config, collate_call)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bLmPPFNrOxug","executionInfo":{"status":"ok","timestamp":1601124914866,"user_tz":-120,"elapsed":852,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["def generate_text_greedy(prompt=\"\", max_length=64):\n","  model.eval()\n","  input_ids = tokenizer.encode(\"<|endoftext|>\" + prompt, return_tensors='pt').cuda()\n","  generated_ids = model.generate(input_ids, max_length=max_length).cpu().tolist()\n","\n","  generated_text = [tokenizer.decode(g, skip_special_tokens=True) for g in generated_ids]\n","  return generated_text\n","\n","\n","def generate_text_beam(prompt=\"\", max_length=64, num_beams=5):\n","  model.eval()\n","  input_ids = tokenizer.encode(\"<|endoftext|>\" + prompt, return_tensors='pt').cuda()\n","  generated_ids = model.generate(input_ids, max_length=max_length, num_beams=num_beams,\n","                                 no_repeat_ngram_size=2).cpu().tolist()\n","\n","  generated_text = [tokenizer.decode(g, skip_special_tokens=True) for g in generated_ids]\n","  return generated_text\n","\n","\n","def generate_text_sampling(prompt=\"\", max_length=64, top_k=50, top_p=0.95, temp=1.0, num_return=1):\n","  model.eval()\n","  input_ids = tokenizer.encode(\"<|endoftext|>\" + prompt, return_tensors='pt').cuda()\n","  generated_ids = model.generate(input_ids, do_sample=True, max_length=max_length, temperature=temp, \n","                                 top_k=top_k, top_p=top_p, num_return_sequences=num_return).cpu().tolist()\n","\n","  generated_text = [tokenizer.decode(g, skip_special_tokens=True) for g in generated_ids]\n","  return generated_text"],"execution_count":126,"outputs":[]},{"cell_type":"code","metadata":{"id":"wO_vLJg6RYi3","executionInfo":{"status":"ok","timestamp":1601125094716,"user_tz":-120,"elapsed":1608,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}},"outputId":"192c2f59-6937-48cb-f023-666247321904","colab":{"base_uri":"https://localhost:8080/","height":146}},"source":["print(generate_text_greedy())\n","print(generate_text_beam())\n","print(generate_text_sampling(num_return=3))"],"execution_count":130,"outputs":[{"output_type":"stream","text":["Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"],"name":"stderr"},{"output_type":"stream","text":["['The best way to get lost in the beauty of life is to be yourself.']\n"],"name":"stdout"},{"output_type":"stream","text":["Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"],"name":"stderr"},{"output_type":"stream","text":["[\"If you want to be a success, you must be willing to take risks. If you don't, chances are you won't be successful.\"]\n","['The worst kind of revenge is when you beat up someone because they were not responsible for his/her bad actions.', 'I used to believe all things were just a dream. Now I know they were real when you believe everything is real.', 'Your thoughts and actions shape your future. You are what you think and you are what you do.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZzamqIxGdB5-","executionInfo":{"status":"ok","timestamp":1601128782535,"user_tz":-120,"elapsed":1428,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}},"outputId":"49d06022-ef0e-4702-e624-7af502e7e3f6","colab":{"base_uri":"https://localhost:8080/","height":90}},"source":["generate_text_sampling(num_return=3, top_k=50, top_p=0.95, temp=1.0)"],"execution_count":144,"outputs":[{"output_type":"stream","text":["Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["[\"If we don't let someone take us to the right place, we're dead.\",\n"," 'The beauty of life is that it is so simple.',\n"," 'I always feel safe, because I know my life is mine.']"]},"metadata":{"tags":[]},"execution_count":144}]},{"cell_type":"code","metadata":{"id":"0w8uKZ_OBTnK","executionInfo":{"status":"error","timestamp":1601118354210,"user_tz":-120,"elapsed":1287,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}},"outputId":"07efb18d-85c6-4d86-bc6d-8e2086a972f7","colab":{"base_uri":"https://localhost:8080/","height":171}},"source":["1 / 0"],"execution_count":79,"outputs":[{"output_type":"error","ename":"ZeroDivisionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-79-bc757c3fda29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"]}]},{"cell_type":"code","metadata":{"id":"--_47QmRBVUr","executionInfo":{"status":"ok","timestamp":1601118357139,"user_tz":-120,"elapsed":2590,"user":{"displayName":"Nadal Bozemili","photoUrl":"","userId":"03871867374575970479"}}},"source":["model = None\n","train_dataloder = None\n","epoch_iterator = None\n","x, y = None, None\n","loss, optimizer = None, None\n","logits_y = None\n","scheduler = None\n","import gc\n","gc.collect()\n","torch.cuda.empty_cache()"],"execution_count":80,"outputs":[]}]}